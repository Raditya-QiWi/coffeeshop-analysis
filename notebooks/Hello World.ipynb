{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c1cf71-7d29-457c-af54-972751705dc9",
   "metadata": {},
   "source": [
    "# Berkenalan Singkat Dengan Minilake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43271483-4293-4c70-bb90-4646456dbaf6",
   "metadata": {},
   "source": [
    "## Sepintas Mengenai Sistem Operasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4a09279-d1eb-408f-9e7a-3616e83ec3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRETTY_NAME=\"Debian GNU/Linux 11 (bullseye)\"\n",
      "NAME=\"Debian GNU/Linux\"\n",
      "VERSION_ID=\"11\"\n",
      "VERSION=\"11 (bullseye)\"\n",
      "VERSION_CODENAME=bullseye\n",
      "ID=debian\n",
      "HOME_URL=\"https://www.debian.org/\"\n",
      "SUPPORT_URL=\"https://www.debian.org/support\"\n",
      "BUG_REPORT_URL=\"https://bugs.debian.org/\"\n"
     ]
    }
   ],
   "source": [
    "! cat /etc/os-release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee20ce9d-fe3f-49f3-acde-dc55ca7216d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n"
     ]
    }
   ],
   "source": [
    "! whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc7a7c5e-aa7a-403a-a95b-7cc215f5ac00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/iceberg/notebooks\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef4d548-12f5-4b21-8a28-3feabb3ab118",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 100M\n",
      "drwxrwxrwx 1 root    root    4.0K Aug  8 16:40  .\n",
      "drwxr-xr-x 1 iceberg iceberg 4.0K Aug  8 16:06  ..\n",
      "drwx------ 1 root    root    4.0K Aug  2 08:16  .Trash-0\n",
      "drwxrwxrwx 1 root    root    4.0K Aug  4 08:55  .git\n",
      "drwxr-xr-x 1 root    root    4.0K Aug  8 13:57  .ipynb_checkpoints\n",
      "-rw-r--r-- 1 root    root     89K Aug  8 16:28 'Business Questions.ipynb'\n",
      "-rw-r--r-- 1 root    root     109 Aug  4 04:28  Cabang.csv\n",
      "-rw-r--r-- 1 root    root     81K Aug  8 16:40  CoffeeShop.ipynb\n",
      "-rwxrwxrwx 1 root    root     37K Aug  8 14:32 'Hello World.ipynb'\n",
      "-rw-r--r-- 1 root    root      48 Aug  4 04:29  Kategori.csv\n",
      "-rw-r--r-- 1 root    root     321 Aug  4 04:29  Produk.csv\n",
      "-rwxrwxrwx 1 root    root    9.7K Jul 31 16:02 'Spark - 01. RDD vs DataFrame.ipynb'\n",
      "-rw-r--r-- 1 root    root    100M Aug  4 03:06  Transaksi.csv\n",
      "drwxr-xr-x 1 root    root    4.0K Aug  1 07:39  spark-warehouse\n"
     ]
    }
   ],
   "source": [
    "!ls -lah"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c03db3-1291-416c-98dd-0173c47e1551",
   "metadata": {},
   "source": [
    "## Tentang Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7de1b2a7-4774-47f7-b139-415e07f4555f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://828a7eb6b33f:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.6</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f7a52c08650>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3983b85-83be-4c64-b5ba-d6d5cb30bd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PySparkShell'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.app.name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "835e7d8a-662d-4a85-939b-76df1f6dc76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local[*]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.master\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6157543-7f6c-4586-b855-56a0c0a638e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in-memory'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.catalogImplementation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbe25660-4f09-4101-9c9b-36a0845d8eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'minilake'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.currentCatalog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "690e48c0-b7f1-41c6-9db4-e3986d603583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://minilake:8181'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.catalog.minilake.uri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d30a66b-0f32-48e9-b89e-6ca0ec26c8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL Spark Web UI Anda adalah: http://828a7eb6b33f:4042\n"
     ]
    }
   ],
   "source": [
    "# 1. Dapatkan SparkContext dari SparkSession Anda\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# 2. Akses atribut .uiWebUrl untuk mendapatkan alamatnya\n",
    "spark_ui_url = sc.uiWebUrl\n",
    "\n",
    "# 3. Cetak hasilnya\n",
    "print(f\"URL Spark Web UI Anda adalah: {spark_ui_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf51bbd4-9fba-41c9-81fe-c0dd94019fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ IP Publik server Anda adalah: 158.140.175.193\n",
      "Coba akses Spark UI di: http://158.140.175.193:4041\n"
     ]
    }
   ],
   "source": [
    "# Perintah ini akan menjalankan command 'curl' dari dalam lingkungan Spark\n",
    "# untuk menanyakan IP publiknya ke layanan ifconfig.me\n",
    "import os\n",
    "host_ip = os.popen('curl -s ifconfig.me').read()\n",
    "\n",
    "# Cetak hasilnya\n",
    "print(f\"✅ IP Publik server Anda adalah: {host_ip}\")\n",
    "\n",
    "# Anda bisa coba membuat URL yang bisa diakses\n",
    "# Ganti port 4041 dengan port yang ditampilkan di output Anda sebelumnya\n",
    "print(f\"Coba akses Spark UI di: http://{host_ip.strip()}:4041\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a690cd-3dea-4bdc-9a13-66e05c4c8606",
   "metadata": {},
   "source": [
    "## Say Hello to Iceberg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4ec1db-9763-4eb2-9dbe-6251e69c189f",
   "metadata": {},
   "source": [
    "Menampilkan semua catalog yang ada pada Iceberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e555d9f6-260f-4fdc-83ca-594e7c3ce1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>catalog</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>minilake</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>spark_catalog</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------------+\n",
       "|       catalog |\n",
       "+---------------+\n",
       "|      minilake |\n",
       "| spark_catalog |\n",
       "+---------------+"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SHOW CATALOGS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bf42ab-392a-470f-b160-c12b8df71622",
   "metadata": {},
   "source": [
    "Menampilkan semua database pada Iceberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b916dd96-85d5-456d-ba60-94cd67ed3be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>namespace</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>coffeeshop</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>coffeeshop_medallion</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>default</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>sample</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>test</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+----------------------+\n",
       "|            namespace |\n",
       "+----------------------+\n",
       "|           coffeeshop |\n",
       "| coffeeshop_medallion |\n",
       "|              default |\n",
       "|               sample |\n",
       "|                 test |\n",
       "+----------------------+"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SHOW DATABASES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baa8c47-2136-4c5e-b429-7f724082ce5c",
   "metadata": {},
   "source": [
    "### Membuat Database dan Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f2a6d60-5c11-4669-8bda-1357923efab1",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o36.sql.\n: org.apache.iceberg.exceptions.ServiceFailureException: Server error: UncheckedSQLException: Failed to execute: INSERT INTO iceberg_namespace_properties (catalog_name, namespace, property_key, property_value) VALUES (?,?,?,?), (?,?,?,?)\n\tat org.apache.iceberg.rest.ErrorHandlers$DefaultErrorHandler.accept(ErrorHandlers.java:241)\n\tat org.apache.iceberg.rest.ErrorHandlers$NamespaceErrorHandler.accept(ErrorHandlers.java:190)\n\tat org.apache.iceberg.rest.ErrorHandlers$NamespaceErrorHandler.accept(ErrorHandlers.java:171)\n\tat org.apache.iceberg.rest.HTTPClient.throwFailure(HTTPClient.java:215)\n\tat org.apache.iceberg.rest.HTTPClient.execute(HTTPClient.java:299)\n\tat org.apache.iceberg.rest.BaseHTTPClient.post(BaseHTTPClient.java:88)\n\tat org.apache.iceberg.rest.RESTSessionCatalog.createNamespace(RESTSessionCatalog.java:548)\n\tat org.apache.iceberg.catalog.BaseSessionCatalog$AsCatalog.createNamespace(BaseSessionCatalog.java:128)\n\tat org.apache.iceberg.rest.RESTCatalog.createNamespace(RESTCatalog.java:227)\n\tat org.apache.iceberg.spark.SparkCatalog.createNamespace(SparkCatalog.java:481)\n\tat org.apache.spark.sql.execution.datasources.v2.CreateNamespaceExec.run(CreateNamespaceExec.scala:47)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msql\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mCREATE DATABASE IF NOT EXISTS sample1\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2565\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2564\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2568\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2569\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.ipython/profile_default/startup/00-prettytables.py:81\u001b[39m, in \u001b[36msql\u001b[39m\u001b[34m(line, cell)\u001b[39m\n\u001b[32m     79\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _to_table(df, num_rows=args.limit)\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _to_table(\u001b[43mspark\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/pyspark/sql/session.py:1631\u001b[39m, in \u001b[36mSparkSession.sql\u001b[39m\u001b[34m(self, sqlQuery, args, **kwargs)\u001b[39m\n\u001b[32m   1627\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1628\u001b[39m         litArgs = \u001b[38;5;28mself\u001b[39m._jvm.PythonUtils.toArray(\n\u001b[32m   1629\u001b[39m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[32m   1630\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1631\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jsparkSession\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1632\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1633\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/pyspark/errors/exceptions/captured.py:179\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdeco\u001b[39m(*a: Any, **kw: Any) -> Any:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    181\u001b[39m         converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    324\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    327\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    328\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    331\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    332\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling o36.sql.\n: org.apache.iceberg.exceptions.ServiceFailureException: Server error: UncheckedSQLException: Failed to execute: INSERT INTO iceberg_namespace_properties (catalog_name, namespace, property_key, property_value) VALUES (?,?,?,?), (?,?,?,?)\n\tat org.apache.iceberg.rest.ErrorHandlers$DefaultErrorHandler.accept(ErrorHandlers.java:241)\n\tat org.apache.iceberg.rest.ErrorHandlers$NamespaceErrorHandler.accept(ErrorHandlers.java:190)\n\tat org.apache.iceberg.rest.ErrorHandlers$NamespaceErrorHandler.accept(ErrorHandlers.java:171)\n\tat org.apache.iceberg.rest.HTTPClient.throwFailure(HTTPClient.java:215)\n\tat org.apache.iceberg.rest.HTTPClient.execute(HTTPClient.java:299)\n\tat org.apache.iceberg.rest.BaseHTTPClient.post(BaseHTTPClient.java:88)\n\tat org.apache.iceberg.rest.RESTSessionCatalog.createNamespace(RESTSessionCatalog.java:548)\n\tat org.apache.iceberg.catalog.BaseSessionCatalog$AsCatalog.createNamespace(BaseSessionCatalog.java:128)\n\tat org.apache.iceberg.rest.RESTCatalog.createNamespace(RESTCatalog.java:227)\n\tat org.apache.iceberg.spark.SparkCatalog.createNamespace(SparkCatalog.java:481)\n\tat org.apache.spark.sql.execution.datasources.v2.CreateNamespaceExec.run(CreateNamespaceExec.scala:47)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "    \n",
    "CREATE DATABASE IF NOT EXISTS sample1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3d77105-cf44-4576-a450-08632a98611f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>namespace</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>coffeeshop</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>coffeeshop_medallion</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>default</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>sample</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>test</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+----------------------+\n",
       "|            namespace |\n",
       "+----------------------+\n",
       "|           coffeeshop |\n",
       "| coffeeshop_medallion |\n",
       "|              default |\n",
       "|               sample |\n",
       "|                 test |\n",
       "+----------------------+"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SHOW DATABASES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f4988b-96c8-448a-8de8-d34b94ad0a91",
   "metadata": {},
   "source": [
    "Membuat tabel  `weather`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "204cc617-c769-4feb-9aaf-d1e3d040b8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE IF NOT EXISTS sample.weather (\n",
    "    datetime              timestamp,\n",
    "    temp                  double,\n",
    "    lat                   double,\n",
    "    long                  double,\n",
    "    cloud_coverage        string,\n",
    "    precip                double,\n",
    "    wind_speed            double\n",
    ")\n",
    "USING iceberg\n",
    "PARTITIONED BY (days(datetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50e7d3ec-d27d-4247-b0c1-87d3694671ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>col_name</th>\n",
       "            <th>data_type</th>\n",
       "            <th>comment</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>datetime</td>\n",
       "            <td>timestamp</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>temp</td>\n",
       "            <td>double</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>lat</td>\n",
       "            <td>double</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>long</td>\n",
       "            <td>double</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>cloud_coverage</td>\n",
       "            <td>string</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>precip</td>\n",
       "            <td>double</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>wind_speed</td>\n",
       "            <td>double</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td># Partitioning</td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Part 0</td>\n",
       "            <td>days(datetime)</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td># Metadata Columns</td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>_spec_id</td>\n",
       "            <td>int</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>_partition</td>\n",
       "            <td>struct&lt;datetime_day:date&gt;</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>_file</td>\n",
       "            <td>string</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>_pos</td>\n",
       "            <td>bigint</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>_deleted</td>\n",
       "            <td>boolean</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td># Detailed Table Information</td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Name</td>\n",
       "            <td>minilake.sample.weather</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Type</td>\n",
       "            <td>MANAGED</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Location</td>\n",
       "            <td>s3://warehouse/sample/weather</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Provider</td>\n",
       "            <td>iceberg</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Owner</td>\n",
       "            <td>root</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Table Properties</td>\n",
       "            <td>[current-snapshot-id=7237277411764345586,format=iceberg/parquet,format-version=2,write.parquet.compression-codec=zstd]</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+------------------------------+------------------------------------------------------------------------------------------------------------------------+---------+\n",
       "|                     col_name |                                                                                                              data_type | comment |\n",
       "+------------------------------+------------------------------------------------------------------------------------------------------------------------+---------+\n",
       "|                     datetime |                                                                                                              timestamp |    None |\n",
       "|                         temp |                                                                                                                 double |    None |\n",
       "|                          lat |                                                                                                                 double |    None |\n",
       "|                         long |                                                                                                                 double |    None |\n",
       "|               cloud_coverage |                                                                                                                 string |    None |\n",
       "|                       precip |                                                                                                                 double |    None |\n",
       "|                   wind_speed |                                                                                                                 double |    None |\n",
       "|                              |                                                                                                                        |         |\n",
       "|               # Partitioning |                                                                                                                        |         |\n",
       "|                       Part 0 |                                                                                                         days(datetime) |         |\n",
       "|                              |                                                                                                                        |         |\n",
       "|           # Metadata Columns |                                                                                                                        |         |\n",
       "|                     _spec_id |                                                                                                                    int |         |\n",
       "|                   _partition |                                                                                              struct<datetime_day:date> |         |\n",
       "|                        _file |                                                                                                                 string |         |\n",
       "|                         _pos |                                                                                                                 bigint |         |\n",
       "|                     _deleted |                                                                                                                boolean |         |\n",
       "|                              |                                                                                                                        |         |\n",
       "| # Detailed Table Information |                                                                                                                        |         |\n",
       "|                         Name |                                                                                                minilake.sample.weather |         |\n",
       "|                         Type |                                                                                                                MANAGED |         |\n",
       "|                     Location |                                                                                          s3://warehouse/sample/weather |         |\n",
       "|                     Provider |                                                                                                                iceberg |         |\n",
       "|                        Owner |                                                                                                                   root |         |\n",
       "|             Table Properties | [current-snapshot-id=7237277411764345586,format=iceberg/parquet,format-version=2,write.parquet.compression-codec=zstd] |         |\n",
       "+------------------------------+------------------------------------------------------------------------------------------------------------------------+---------+"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "DESCRIBE TABLE EXTENDED sample.weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e9432f0-a853-4d4a-ad83-a907c4982ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>datetime</th>\n",
       "            <th>temp</th>\n",
       "            <th>lat</th>\n",
       "            <th>long</th>\n",
       "            <th>cloud_coverage</th>\n",
       "            <th>precip</th>\n",
       "            <th>wind_speed</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>2023-08-16 00:00:00</td>\n",
       "            <td>76.2</td>\n",
       "            <td>40.951908</td>\n",
       "            <td>-74.075272</td>\n",
       "            <td>Partially sunny</td>\n",
       "            <td>0.0</td>\n",
       "            <td>3.5</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-08-16 00:00:00</td>\n",
       "            <td>76.2</td>\n",
       "            <td>40.951908</td>\n",
       "            <td>-74.075272</td>\n",
       "            <td>Partially sunny</td>\n",
       "            <td>0.0</td>\n",
       "            <td>3.5</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-08-17 00:00:00</td>\n",
       "            <td>82.5</td>\n",
       "            <td>40.951908</td>\n",
       "            <td>-74.075272</td>\n",
       "            <td>Sunny</td>\n",
       "            <td>0.0</td>\n",
       "            <td>1.2</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-08-17 00:00:00</td>\n",
       "            <td>82.5</td>\n",
       "            <td>40.951908</td>\n",
       "            <td>-74.075272</td>\n",
       "            <td>Sunny</td>\n",
       "            <td>0.0</td>\n",
       "            <td>1.2</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-08-18 00:00:00</td>\n",
       "            <td>70.9</td>\n",
       "            <td>40.951908</td>\n",
       "            <td>-74.075272</td>\n",
       "            <td>Cloudy</td>\n",
       "            <td>0.5</td>\n",
       "            <td>5.2</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-08-18 00:00:00</td>\n",
       "            <td>70.9</td>\n",
       "            <td>40.951908</td>\n",
       "            <td>-74.075272</td>\n",
       "            <td>Cloudy</td>\n",
       "            <td>0.5</td>\n",
       "            <td>5.2</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------------------+------+-----------+------------+-----------------+--------+------------+\n",
       "|            datetime | temp |       lat |       long |  cloud_coverage | precip | wind_speed |\n",
       "+---------------------+------+-----------+------------+-----------------+--------+------------+\n",
       "| 2023-08-16 00:00:00 | 76.2 | 40.951908 | -74.075272 | Partially sunny |    0.0 |        3.5 |\n",
       "| 2023-08-16 00:00:00 | 76.2 | 40.951908 | -74.075272 | Partially sunny |    0.0 |        3.5 |\n",
       "| 2023-08-17 00:00:00 | 82.5 | 40.951908 | -74.075272 |           Sunny |    0.0 |        1.2 |\n",
       "| 2023-08-17 00:00:00 | 82.5 | 40.951908 | -74.075272 |           Sunny |    0.0 |        1.2 |\n",
       "| 2023-08-18 00:00:00 | 70.9 | 40.951908 | -74.075272 |          Cloudy |    0.5 |        5.2 |\n",
       "| 2023-08-18 00:00:00 | 70.9 | 40.951908 | -74.075272 |          Cloudy |    0.5 |        5.2 |\n",
       "+---------------------+------+-----------+------------+-----------------+--------+------------+"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM sample.weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce275c12-334c-41d0-ab81-0ecd19b5a812",
   "metadata": {},
   "source": [
    "Mengupload contoh data dari dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "772aa2d9-446b-4b3c-ac1a-b7038cc3a363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "schema = spark.table(\"sample.weather\").schema\n",
    "\n",
    "data = [\n",
    "    (datetime(2023,8,16), 76.2, 40.951908, -74.075272, \"Partially sunny\", 0.0, 3.5),\n",
    "    (datetime(2023,8,17), 82.5, 40.951908, -74.075272, \"Sunny\", 0.0, 1.2),\n",
    "    (datetime(2023,8,18), 70.9, 40.951908, -74.075272, \"Cloudy\", .5, 5.2)\n",
    "  ]\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.writeTo(\"sample.weather\").append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d40646b-acca-48cd-b70d-40a3642b01db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>datetime</th>\n",
       "            <th>temp</th>\n",
       "            <th>lat</th>\n",
       "            <th>long</th>\n",
       "            <th>cloud_coverage</th>\n",
       "            <th>precip</th>\n",
       "            <th>wind_speed</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>2023-08-16 00:00:00</td>\n",
       "            <td>76.2</td>\n",
       "            <td>40.951908</td>\n",
       "            <td>-74.075272</td>\n",
       "            <td>Partially sunny</td>\n",
       "            <td>0.0</td>\n",
       "            <td>3.5</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-08-17 00:00:00</td>\n",
       "            <td>82.5</td>\n",
       "            <td>40.951908</td>\n",
       "            <td>-74.075272</td>\n",
       "            <td>Sunny</td>\n",
       "            <td>0.0</td>\n",
       "            <td>1.2</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-08-16 00:00:00</td>\n",
       "            <td>76.2</td>\n",
       "            <td>40.951908</td>\n",
       "            <td>-74.075272</td>\n",
       "            <td>Partially sunny</td>\n",
       "            <td>0.0</td>\n",
       "            <td>3.5</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-08-18 00:00:00</td>\n",
       "            <td>70.9</td>\n",
       "            <td>40.951908</td>\n",
       "            <td>-74.075272</td>\n",
       "            <td>Cloudy</td>\n",
       "            <td>0.5</td>\n",
       "            <td>5.2</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-08-17 00:00:00</td>\n",
       "            <td>82.5</td>\n",
       "            <td>40.951908</td>\n",
       "            <td>-74.075272</td>\n",
       "            <td>Sunny</td>\n",
       "            <td>0.0</td>\n",
       "            <td>1.2</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-08-18 00:00:00</td>\n",
       "            <td>70.9</td>\n",
       "            <td>40.951908</td>\n",
       "            <td>-74.075272</td>\n",
       "            <td>Cloudy</td>\n",
       "            <td>0.5</td>\n",
       "            <td>5.2</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-08-16 00:00:00</td>\n",
       "            <td>76.2</td>\n",
       "            <td>40.951908</td>\n",
       "            <td>-74.075272</td>\n",
       "            <td>Partially sunny</td>\n",
       "            <td>0.0</td>\n",
       "            <td>3.5</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-08-17 00:00:00</td>\n",
       "            <td>82.5</td>\n",
       "            <td>40.951908</td>\n",
       "            <td>-74.075272</td>\n",
       "            <td>Sunny</td>\n",
       "            <td>0.0</td>\n",
       "            <td>1.2</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-08-18 00:00:00</td>\n",
       "            <td>70.9</td>\n",
       "            <td>40.951908</td>\n",
       "            <td>-74.075272</td>\n",
       "            <td>Cloudy</td>\n",
       "            <td>0.5</td>\n",
       "            <td>5.2</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------------------+------+-----------+------------+-----------------+--------+------------+\n",
       "|            datetime | temp |       lat |       long |  cloud_coverage | precip | wind_speed |\n",
       "+---------------------+------+-----------+------------+-----------------+--------+------------+\n",
       "| 2023-08-16 00:00:00 | 76.2 | 40.951908 | -74.075272 | Partially sunny |    0.0 |        3.5 |\n",
       "| 2023-08-17 00:00:00 | 82.5 | 40.951908 | -74.075272 |           Sunny |    0.0 |        1.2 |\n",
       "| 2023-08-16 00:00:00 | 76.2 | 40.951908 | -74.075272 | Partially sunny |    0.0 |        3.5 |\n",
       "| 2023-08-18 00:00:00 | 70.9 | 40.951908 | -74.075272 |          Cloudy |    0.5 |        5.2 |\n",
       "| 2023-08-17 00:00:00 | 82.5 | 40.951908 | -74.075272 |           Sunny |    0.0 |        1.2 |\n",
       "| 2023-08-18 00:00:00 | 70.9 | 40.951908 | -74.075272 |          Cloudy |    0.5 |        5.2 |\n",
       "| 2023-08-16 00:00:00 | 76.2 | 40.951908 | -74.075272 | Partially sunny |    0.0 |        3.5 |\n",
       "| 2023-08-17 00:00:00 | 82.5 | 40.951908 | -74.075272 |           Sunny |    0.0 |        1.2 |\n",
       "| 2023-08-18 00:00:00 | 70.9 | 40.951908 | -74.075272 |          Cloudy |    0.5 |        5.2 |\n",
       "+---------------------+------+-----------+------------+-----------------+--------+------------+"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM sample.weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0c1a99-0906-489b-8804-a92c282653bc",
   "metadata": {},
   "source": [
    "Agregasi sederhana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1da37aab-5893-4f6c-a7a9-21cb65efb4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>cloud_coverage</th>\n",
       "            <th>count(1)</th>\n",
       "            <th>sum(temp)</th>\n",
       "            <th>avg(precip)</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Cloudy</td>\n",
       "            <td>3</td>\n",
       "            <td>212.70000000000002</td>\n",
       "            <td>0.5</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Partially sunny</td>\n",
       "            <td>3</td>\n",
       "            <td>228.60000000000002</td>\n",
       "            <td>0.0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Sunny</td>\n",
       "            <td>3</td>\n",
       "            <td>247.5</td>\n",
       "            <td>0.0</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-----------------+----------+--------------------+-------------+\n",
       "|  cloud_coverage | count(1) |          sum(temp) | avg(precip) |\n",
       "+-----------------+----------+--------------------+-------------+\n",
       "|          Cloudy |        3 | 212.70000000000002 |         0.5 |\n",
       "| Partially sunny |        3 | 228.60000000000002 |         0.0 |\n",
       "|           Sunny |        3 |              247.5 |         0.0 |\n",
       "+-----------------+----------+--------------------+-------------+"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT cloud_coverage, count(*), sum(temp), avg(precip)\n",
    "FROM sample.weather\n",
    "GROUP BY cloud_coverage\n",
    "ORDER BY cloud_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b89caf-ca3b-44b0-8757-316e3c7294a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
